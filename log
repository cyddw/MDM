6.13
1.安装FFmpeg

6.18
1.完成报错Can't pickle local object 'get_collate_fn.<locals>.<lambda>

6.19
1.完成MDM模型采样输出获取
2.完成对本文涉及的数据集的分析
3.完成对模型的损失函数分析
4.完成对模型的263个关节向量和1个特征的分析

6.20
1.为什么要将22个关节在空间的绝对位置转为263维度？(便于后续的处理，已完成)
2.完成对MDM模型输入的22*3以及263数据在模型内部的处理逻辑的分析(MDM模型输入不包括22*3，只有263维度的数据)
3.完成对MDM模型的loss的分析(计算loss时的target和生成的x_start都是263维度？是的，都是263维度。为什么采样输出为22*3？采样输出263维度，经过转化后得到22*3维度)
4.正在考虑如何将22*3维度的数据转为263维度(已完成)
5.正在探究MDM代码中是如何进行采样扩散的(已完成)
6.正在获取humanml3d的原始数据(已完成)
7.正在生成90个样本对应的vec，但是循环过程中遇到多次0-90的加载过程(已完成)

6.23
1.正在探究如何实现无条件扩散(已完成)
2.原文代码是否有误(--cond_mask_prob 0)(已完成，没问题)
3.损失函数中各类lamda的设置(已完成)
4.能否直接使用Humanml3d数据集进行无条件扩散？(先弄清楚HumanACT12输入数据的组成)
5.pose和joint3d分别代表什么？(已完成，joint3d表示关节的xyz坐标，pose表示姿态参数，即轴角表示，其中包括全局旋转表示和其他关节相对于根关节的旋转表示)
6.uncond下的cond全为True，其是如何传递至model，使其不编码text？(已完成)

6.24
1.正在复现从坐标到姿态参数的处理(已完成)
2.将mesh数据处理成可以被mdm读取的格式(已完成)

6.25
1.为什么iter=595？(已完成)
2.尝试将人体骨架mesh化(已完成)
3.为什么文件不存在？(已完成)
4.代码需要在服务器上运行(已完成)
5.下载blender(已完成)
6.如何将obj文件转为mp4(已完成)

6.26
1.获取在自己数据集下生成的mesh(已完成)
2.尝试跑通eval代码(已跑通unconditional的代码，但是需要时间太久，6h左右)
3.弄清各项评估指标的含义(已完成)
4.MDM模型中mask的目的是什么？(已完成，在训练的过程中包括有条件和无条件，以增强模型生成的多样性)

6.27
1.调试Linux服务器，并对代码环境进行测试(已完成)
2.服务器上跑代码(已完成)

6.30
1.学习TCN的相关概念(已完成)
2.学习自编码和变分自编码的相关概念(已完成)
3.完成模型整体思路构建(已完成)
4.MDM运行结果查看(已完成)
5.构建ARMD虚拟环境(已完成)

7.1
1.梳理模型整体思路以及细节(已完成)
2.尝试初步建模输入部分(已完成噪声和data的输入部分)
3.尝试修改前向传播部分(已完成)

7.2
1.逐步修改前向传播部分的代码(已完成训练部分的模型输出部分)
2.尝试修改训练部分的loss更新部分(已完成训练部分的所有内容)
3.尝试采样部分代码的修改(两个问题:1.为什么ARMD采样部分的代码是直接由X_T生成X_0的  2.pred_len、num_timesteps、seq_length、timesteps、seq_len的含义是什么)(关于问题2，具体含义是什么好像并不重要，只要知道其具体的工作原理，并将其嵌套进自己的模型中即可)
4.我的模型存在一个很致命的问题：每个样本只有最后60帧能被更新到(后续可能要改进，具体先看看模型跑出来的效果)

7.4
1.有一个疑问(在DDPM和DDIM中，都是基于加噪为高斯噪声的假设，而在ARMD中并未基于这个假设，那么论文中能用DDPM和DDIM的结论？)
2.检查并思考代码修改部分(已完成)

7.5
1.看3DGS论文
2.ARMDM模型跑了10w步还是乱码的，需要仔细查看并修改(已完成)
3.有一个疑问(因为模型是每隔60帧输出，那么输出的前60帧和后60帧是否不连贯？)
4.尝试将采样过程中的第0帧输入换成数据集的平均值，是否可行？
5.无条件采样中，输入的是(3,25,6,60)，输出是(24,3)形式还是(25,6)形式？(经过转换，输出是(24,3)形式)

7.7
1.ARMDM模型跑了20w步之后的效果仍然很差，思考能否从generate部分入手，将generate的扩散部分改为一步扩散(已完成，效果也不行，基本和输入保持一致)
2.检查ARMDM模型的训练过程是否修改有误(已完成，没有问题)
3.个人感觉是训练的loss应该设置为预测的噪声比较好(已完成，目前看来效果有改善)

7.8
1.尝试将前60帧进行复制，看看跑出来的效果(已完成)
2.下一步工作：看real-time diffusion等相关论文，看有无解决思路

7.9
1.等待代码运行结果中
2.尝试cond代码的修改(已完成)

7.10
1.查看代码中cond['y']['lengths']和cond['y']['mask']参数的作用(已完成，其中'mask'并不代表cond和uncond的比例，而是表示补齐帧和实际帧的比例)
2.看论文DiffMesh

7.14
1.弄清楚DiffMesh的模型(已完成)
2.ARMDM(0.1 trendloss substitute rotmse with previous 1 frames)：将60帧60帧的生成改成1帧1帧生成，同时给定的输入也由60帧改为1帧(1帧为训练集的前1帧)
3.已完成对loss写入csv的修改(已完成)

7.15
1.修改代码并运行(已完成)
2.尝试初步运行了一下1帧1帧输入的代码(500步)，发现最后一帧会跳帧，感觉还是loss的问题，loss应该覆盖整个GT(已完成)
3.为什么trend_mse这么小，应该是那里有问题，建议检查一下(已完成，确实有问题，需要进行一定的修改，不过在similar to DiffMesh中不用考虑trend_loss，可以注释掉)
4.generate生成的是前59帧还是后59帧(后59帧)
5.感觉给的数据集有问题，生成的GT有一半都是不动的(已将Data_loader的shuffle改为False)(已完成，数据集没问题，可能跟自己的数据集有关，采样得到的60帧不是前60帧，导致部分动画静止不动)
6.生成的GT和实际动作有出入(有较大延迟)(已完成)

7.16
1.已经找到数据集GT静止的大致原因(已完成，应该是将joints转为rot和将rot转回joints的函数有点问题，可能跟cam的位置有关系)
2.静止和延迟问题已解决(已完成)
3.增加训练步数，看看效果，同时更改loss(已完成,等待结果中)

7.18
1.进度整理(已完成)
2.尝试使用MDM模型生成采样的第一帧(已完成，效果不错)
3.进展修改(已完成)

7.21
1.弄清楚MDM的condition情形在代码中是如何实现的(已完成)
2.当前阶段任务：如何处理CSI从而得到condition
3.查找有无相关论文(已完成)

7.22
1.安装Wifi3d代码环境和依赖(已完成，代码写的太烂了，看不明白具体调用过程)
2.实现对csi的去噪操作(无法完成)

7.23
1.讨论汇总：
对模型5进行修正(将原有的60帧改为4帧，但是保证4帧的扩散步数仍然是60步)；
处理condition，首先进行去噪操作(不对幅值进行操作，只关注于csi的相位)，然后对每个receiver获取其AoA(注意，transmitter有四根天线，四根天线发送的信号是相互正交的)，最后通过各个receiver的相对位置计算得到最终的AoA；
关注diffusion flow的相关论文

7.24
1.看最小二乘线性回归算法(已完成)
2.初步完成相位去噪算法(已完成，问题1：去噪后的相位在某些子载波处发生跳变)
3.VQ-VAE学习(https://sunlin-ai.github.io/2022/06/02/VQ-VAE.html#fn:3)(看了一点)
4.贝叶斯优化学习
5.计算AoA(以UWB-Fi为参考代码)(已完成)

7.25
1.初步完成子载波中心频率划分(问题2：子载波中心频率划分不一定正确)(已完成，修改子载波中心频率的划分规则对输出结果没有影响)
2.初步完成AoA_ToF的提取(问题3：代码运算时间久，可以考虑转为torch)
3.AoA-ToF谱标签修改(已完成)

7.28
1.将代码转为torch版本，以减少运算时间(已完成，但是torch版本相比cpu版本速度提升不大)
2.获取AoA谱、AoA_Doppler谱(已完成)
3.问题汇总：(问题1：为什么aoa_doppler谱只有第一个有图像，问题2：输入csi的维度问题，是(2,1,0)，还是(2,0,1)(问题2已完成))
4.找数据集验证代码是否正确(已完成)
5.弄懂doppler等代码原理

7.29
1.弄懂val_csi的生成过程(已完成，一个直射路径和一个反射路径，直射路径路程为7m，反射路径路程长为7.56m)
2.生成以时间为x轴，AoA为y轴的图像(已完成)
3.看相关论文，思考如何将多个接收机计算的谱进行结合(已完成，初步想法：三角定位+聚类)
4.坐标转换(已完成)

7.30
1.对八个接收机的结果进行合并处理(已完成，没有丝毫效果，生成的AoA-ToF谱本身就不太对，信号源基本都集中在接收机附近，而不是物体附近。可能的原因：csi去噪过程有误；生成AoA-ToF谱的代码有误)
2.看论文video diffusion models


7.31
1.通过matlab生成无噪的csi信号(已完成)
2.看论文spotfi和wifi_localization

8.1
1.看论文wifi_localization(已完成)
2.弄明白https://zhuanlan.zhihu.com/p/611466195(看了一半，包括隐变量模型和能量函数)
3.已完成AoA_ToF代码调试，已解决之前直射路径不存在问题(信号相干，而且角度间隔小(7度左右)，导致两个信号被识别成一个信号)
4.接下来的任务：探究unwrap和去噪对结果的影响；ToF估计是否准确，考虑只用AoA定位(但是如何对信号进行pair？)

8.5
1.对unwrap的信号重新进行wrap(已完成)

8.26
1.是否unwrap对结果是否有影响？(已完成，是否unwrap对结果没有影响)

8.27
1.接下来的工作：一是看RF-diffusion和video-diffusion两篇论文；二是对生成的AoA-ToF进行静态路径的去除，重点还是对diffusion部分的改进

8.28
论文阅读进展：
1.video-diffusion(50%)
2.RF-diffusion
3.UW-wifi sensing(完成，没有过滤操作)
4.widar 2.0(完成，没有过滤操作)
5.tutorial of diffusion(50%)

8.29
1.尝试构建2D-AOA，利用两个接收端的一维AoA进行构建，效果不理想(已完成)
2.尝试用AoA-Doppler代替AoA-ToF，效果还行，且能够过滤掉静态路径分量，但是部分参数设置没弄懂(已完成)
3.已完成高通滤波和全局平均两个消除静态路径的方法，接下来需要分析使用哪个作为最终方案(使用全局平均效果相对好一点)
4.先窗口划分再滤波还是先滤波再窗口划分(先滤波再窗口划分)
5.对于2-1-1-1的例子，后半部分是静止状态，但是dfs并未集中在0hz附近，误差较大，哪里有问题？(不清楚哪里有问题，可能有其他干扰)

9.6
1.跑通mdm_between代码(已完成)
2.跑通reconstruction guidance的代码(已完成)
3.对于reconstruction guidance，修改使其给定初始第一帧(已完成)
4.对于reconstruction guidance，转为text_condition模式(已完成)
5.将自身的数据转为Humanml3d格式(已完成)
6.wifi不完整，mesh数据也不完整，先在小规模数据集上训练:
流程：1.本地data_process/Humanml3d_prc 2.本地data_process/motion_representation 3.将生成的数据转移至dataset/HumanML3D中 4.通过HumanML3D/motion_representation生成绝对值数据 5.通过HumanML3D/cal_mean_variance生成绝对值数据的均值和方差 6.通过others/cal_train_val_test生成txt文件 7.添加text文件夹至HumanML3D文件夹下
     8.添加000021.npy至dataset文件夹下
7.对数据集进行y轴反转(完成)
8.尝试用自身数据集对其进行训练(完成)
9.待完成的工作：1.对比学习模型的确认 2.AoA-DFS数据和Mesh数据的对齐 3.对比学习模型跑通 4.将对比学习模型整合进模型中

9.8
1.设置epoch为24000，等待训练结果
